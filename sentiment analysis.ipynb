{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMsrSEKQxcApjvQOT26dMGq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Sentiment Analysis of Twitter and Reddit Dataset using LSTM"],"metadata":{"id":"JaBCFDQ2nOBZ"}},{"cell_type":"markdown","source":["### Importing all libraries"],"metadata":{"id":"XObCB98vnUN0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ySSmLjYnDq7s"},"outputs":[],"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization\n","import pandas\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","import numpy as np\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","from google.colab import drive\n","from tensorflow.keras import regularizers"]},{"cell_type":"code","source":["nltk.download('punkt')\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V9yKbm3XLj6T","executionInfo":{"status":"ok","timestamp":1692100874588,"user_tz":-330,"elapsed":3,"user":{"displayName":"HARSH JAIN 22BCG10033","userId":"06538466280623958637"}},"outputId":"476b207c-a7ee-477d-9adf-53ce7bc9bc21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["### Reading the downloaded Dataset from Kaggle using pandas\n","(https://www.kaggle.com/datasets/cosmos98twitter-and-reddit-sentimental-analysis-dataset)\n","\n"],"metadata":{"id":"n0dIMK1MnfE4"}},{"cell_type":"code","source":["data_reddit = pandas.read_csv(\"/content/Reddit_Data.csv\")\n","data_twitter = pandas.read_csv(\"/content/Twitter_Data.csv\")\n","data_reddit.rename(columns = {'clean_comment': 'text'}, inplace = True)\n","data_twitter.rename(columns = {'clean_text': 'text'}, inplace = True)\n","\n","data = pandas.concat([data_reddit, data_twitter], ignore_index = True)\n","data = pandas.DataFrame(data)"],"metadata":{"id":"GI6NXz2mFRJL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Removing all Null values"],"metadata":{"id":"P5R-Y5rWoB6j"}},{"cell_type":"code","source":["data.dropna(axis = 0, inplace = True)"],"metadata":{"id":"iK4gxD0O5gqv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Defining Functions to Preorocess and tokenize the dataset\n"],"metadata":{"id":"mUzDMGMeoJSt"}},{"cell_type":"code","source":["def preprocess_text(text):\n","    if isinstance(text, str):  # Check if the text is a non-null string\n","        # Convert text to lowercase\n","        text = text.lower()\n","\n","        # Tokenization\n","        tokens = word_tokenize(text)\n","\n","        # Remove punctuation and non-alphanumeric tokens\n","        tokens = [token for token in tokens if token.isalnum()]\n","\n","        # Remove stopwords\n","        stop_words = set(stopwords.words('english'))\n","        tokens = [token for token in tokens if token not in stop_words]\n","\n","        # Join tokens back into a sentence\n","        preprocessed_text = ' '.join(tokens)\n","\n","        return preprocessed_text\n","    else:\n","        return \"\"  # Return an empty string for NaN or non-string values\n","\n","def tokenize(item):\n","  tokenizer = Tokenizer(oov_token=\"<OOV>\")\n","  tokenizer.fit_on_texts(item)\n","  sequences = tokenizer.texts_to_sequences(item)\n","  max_length = 65  # Choose an appropriate value\n","  padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n","  vocab_size = len(tokenizer.word_index) + 1\n","  return padded_sequences, vocab_size\n","\n","def lr_schedule(epoch, lr):\n","    return lr * np.exp(1)"],"metadata":{"id":"SX1uD1v1LLVG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ordinal Mapping my data as **(-1,0,1)-->(0,1,2)**\n","*This step is optional*"],"metadata":{"id":"qVc6tH8OodA5"}},{"cell_type":"code","source":["ordinal_mapping = {-1: 0, 0: 1, 1: 2}\n","\n","# Apply ordinal encoding to your labels using the apply function\n","data['encoded_sentiment'] = data['category'].apply(lambda x: ordinal_mapping[x])\n","data['preprocessed_text'] = data['text'].apply(preprocess_text)"],"metadata":{"id":"JuAL_vJIWiX3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Tokenizing, Splitting and Converting all data to tensors"],"metadata":{"id":"Exizuqn9o7-8"}},{"cell_type":"code","source":["x = data.pop(\"preprocessed_text\")\n","y = data.pop('encoded_sentiment')\n","x, vocab_size = tokenize(x)\n","y = to_categorical(y, 3)\n","\n","X_train,X_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=42)\n","\n","X_train = tf.convert_to_tensor(X_train)\n","y_train = tf.convert_to_tensor(y_train)\n","X_test = tf.convert_to_tensor(X_test)\n","y_test = tf.convert_to_tensor(y_test)"],"metadata":{"id":"_OMRVnZfvltX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Defining all Callbacks for early stopping and learning rate reduction"],"metadata":{"id":"Bc0xrrckpEru"}},{"cell_type":"code","source":["early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=0, verbose=1, min_lr=1e-6)\n","\n","embedding_dim = 65\n","max_length = 65"],"metadata":{"id":"G0jkivWocbpy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Initilizing sequential model using Recurrent Neural Network\n"],"metadata":{"id":"CZI--xCdpRxd"}},{"cell_type":"code","source":["tf.random.set_seed(42)\n","model = Sequential()\n","model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n","model.add(LSTM(8, return_sequences=True))\n","model.add(BatchNormalization())\n","model.add(Dropout(rate=0.4))\n","model.add(LSTM(8, return_sequences=True))\n","model.add(Dropout(rate=0.4))\n","model.add(LSTM(8, return_sequences=True))\n","model.add(Dropout(rate=0.2))\n","model.add(LSTM(8))\n","model.add(Dropout(rate=0.2))\n","model.add(Dense(3, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.004), metrics=['accuracy'])\n","\n","history = model.fit(X_train, y_train, epochs=25, validation_split=0.2, callbacks=[early_stopping,lr_scheduler])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MS8gn3MSO01G","outputId":"9dcdd324-ea3c-485a-876a-b71232cec785","executionInfo":{"status":"ok","timestamp":1692111335276,"user_tz":-330,"elapsed":572952,"user":{"displayName":"HARSH JAIN 22BCG10033","userId":"06538466280623958637"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","4253/4253 [==============================] - 148s 33ms/step - loss: 0.5035 - accuracy: 0.8179 - val_loss: 0.3216 - val_accuracy: 0.9006 - lr: 0.0040\n","Epoch 2/25\n","4253/4253 [==============================] - 88s 21ms/step - loss: 0.2993 - accuracy: 0.9121 - val_loss: 0.3044 - val_accuracy: 0.9111 - lr: 0.0040\n","Epoch 3/25\n","4253/4253 [==============================] - 86s 20ms/step - loss: 0.2395 - accuracy: 0.9331 - val_loss: 0.2972 - val_accuracy: 0.9131 - lr: 0.0040\n","Epoch 4/25\n","4253/4253 [==============================] - ETA: 0s - loss: 0.2002 - accuracy: 0.9465\n","Epoch 4: ReduceLROnPlateau reducing learning rate to 0.002400000113993883.\n","4253/4253 [==============================] - 82s 19ms/step - loss: 0.2002 - accuracy: 0.9465 - val_loss: 0.3091 - val_accuracy: 0.9109 - lr: 0.0040\n","Epoch 5/25\n","4253/4253 [==============================] - ETA: 0s - loss: 0.1562 - accuracy: 0.9594\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00144000006839633.\n","4253/4253 [==============================] - 85s 20ms/step - loss: 0.1562 - accuracy: 0.9594 - val_loss: 0.3602 - val_accuracy: 0.9025 - lr: 0.0024\n","Epoch 6/25\n","4251/4253 [============================>.] - ETA: 0s - loss: 0.1234 - accuracy: 0.9677\n","Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0008640000130981206.\n","4253/4253 [==============================] - 82s 19ms/step - loss: 0.1234 - accuracy: 0.9677 - val_loss: 0.4089 - val_accuracy: 0.9041 - lr: 0.0014\n"]}]},{"cell_type":"markdown","source":["### Evaluting my model"],"metadata":{"id":"NhBtOOTWp2db"}},{"cell_type":"code","source":["model.evaluate(X_test,y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-boNwS-3kzId","executionInfo":{"status":"ok","timestamp":1692110648450,"user_tz":-330,"elapsed":9629,"user":{"displayName":"HARSH JAIN 22BCG10033","userId":"06538466280623958637"}},"outputId":"679211d1-0427-49a9-d55b-1e407b0d79ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["939/939 [==============================] - 6s 6ms/step - loss: 0.3028 - accuracy: 0.9109\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.3028303384780884, 0.9109201431274414]"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["### Saving it to my Google Drive"],"metadata":{"id":"NCiJkjaGp6_Q"}},{"cell_type":"code","source":["drive.mount('/content/drive')\n","model.save('/content/drive/My Drive/Colab Notebooks/sentiment_analysis_model_combined2.h5')"],"metadata":{"id":"Y7CUI9wpQc9h","executionInfo":{"status":"ok","timestamp":1692110688441,"user_tz":-330,"elapsed":4830,"user":{"displayName":"HARSH JAIN 22BCG10033","userId":"06538466280623958637"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1878f7a3-37d2-43ac-b451-58ca105773fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"OqQL5cq-p4tP"},"execution_count":null,"outputs":[]}]}